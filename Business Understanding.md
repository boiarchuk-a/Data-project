# Проект по машинному обучению: **Модель прогнозирования отклика клиента на скидку**

## 1. Бизнес-анализ (Business Understanding)

**Цель проекта:**
Создать модель машинного обучения, которая прогнозирует вероятность того, что клиент совершит покупку после получения скидки.
Это позволит направлять маркетинговые предложения тем клиентам, у которых выше шанс отклика, и сократить лишние расходы на неэффективные рассылки.

**Проблема:**
Многие компании отправляют скидки всем подряд, не анализируя, кто действительно реагирует.
В результате часть бюджета уходит впустую, а общий эффект от акций снижается.

**Ожидаемый результат:**
Модель, которая присваивает каждому клиенту **оценку вероятности отклика (рейтинг)**.
По этому рейтингу можно выбрать, кому рассылать скидку, а кому нет.

**Основные участники:**

* Студент (Боярчук Алина) — аналитик/разработчик модели.
* Гипотетический маркетинговый отдел — пользователь результатов.

**Существующие модели и подходы:**

* Uplift-модели (Causal ML) — применяются в крупных компаниях для оценки эффекта скидок или рекламы.
Пример: Uplift Random Forest, T-learner, X-learner.
Эти модели не просто предсказывают, купит ли клиент, а оценивают разницу между откликом при наличии и отсутствии скидки.
Используются Amazon, Spotify, AliExpress для персонализации акций.

* Рекомендательные системы — строят предложения и скидки на основе истории покупок других клиентов (например, «похожие товары» или «клиенты, похожие на вас, купили»).
Однако они не всегда оценивают экономическую выгоду скидки.

**Чем отличается мой проект:**

* В моём проекте используется простая классификационная модель (логистическая регрессия или Random Forest),
которая прогнозирует вероятность отклика клиента на скидку, а не сложный каузальный uplift.

* Это учебная и объяснимая версия маркетинговой модели: цель — понять основы отбора клиентов по вероятности покупки.

* Модель не требует больших данных и специальных библиотек (достаточно scikit-learn).

* В отличие от промышленных решений, здесь мы не считаем точный эффект скидки (разницу между «дали» и «не дали»),
а просто определяем, кто наиболее склонен воспользоваться предложением.

### 1.1 Текущая ситуация (Assessing current solution)

**Источники данных:**
Используем открытые наборы данных (для учебного проекта):

* [Hillstrom Email Marketing Dataset (Kaggle)](https://www.kaggle.com/datasets/jackdaoud/marketing-data) — данные о рассылках и покупках клиентов.
* Альтернатива: [In-Vehicle Coupon Recommendation](https://www.kaggle.com/datasets/mathurinache/invehicle-coupon-recommendation/data) — пользователи решают, принять купон или нет.

**Ресурсы:**

* Python, Jupyter Notebook.

**Потенциальные риски:**

* Небольшой размер выборки.
* Дисбаланс классов (мало откликов).
* Ошибки или пропуски в данных.

**Как снизить риски:**

* Применить балансировку классов (`SMOTE` или `class_weight`).
* Провести тщательную очистку данных.
* Использовать простые и интерпретируемые модели (логистическая регрессия, Random Forest).

## 1.2 Цели с точки зрения аналитики (Data Mining Goals)

**Формулировка задачи:**
Построить классификационную модель, предсказывающую вероятность отклика клиента на скидку (0 — не купит, 1 — купит).
Результат используется для **ранжирования клиентов по вероятности отклика**.

**Выбранные модели:**

* Logistic Regression — для интерпретируемости.
* Random Forest — как улучшенный вариант с учётом нелинейных зависимостей.

**Метрики качества:**

* **Accuracy** — доля правильных ответов.
* **Precision** — насколько точно выбрали тех, кто реально откликнется.
* **Recall** — насколько много покупателей модель смогла «поймать».
* **F1-score** — баланс точности и полноты.
* **ROC-AUC** — общая способность модели отличать отклик от отказа.

**Критерий успешности:**

* F1-score ≥ 0.7
* ROC-AUC ≥ 0.75

## 1.3 План проекта (Project Plan)

| Этап                                         | Действия                                                                                     |
| -------------------------------------------- | -------------------------------------------------------------------------------------------- |
| **1. Сбор и подготовка данных**              | Загрузка датасета, очистка данных, проверка пропусков, кодирование категориальных признаков. |
| **2. Исследовательский анализ данных (EDA)** | Построение графиков, проверка распределений, корреляций, баланс классов.                     |
| **3. Построение моделей**                    | Обучение Logistic Regression и Random Forest.                                                |
| **4. Оценка качества**                       | Вычисление Accuracy, Precision, Recall, F1-score, ROC-AUC.                                   |
| **5. Интерпретация результатов**             | Анализ важности признаков, построение топа клиентов с наибольшей вероятностью покупки.       |
| **6. Презентация результатов**               | Подготовка визуализаций и выводов, рекомендации для маркетинга.                              |

### 1.4 Бизнес-метрики и проверка ценности

**Зачем считаю.** Показываю, что таргетированная рассылка (только top-K по скору модели) выгоднее, чем массовая.

**Что считаю (простыми словами):**

* **CR_t** — конверсия **среди тех, кому отправили скидку** («сколько купили со скидкой»).
* **CR_c** — конверсия **среди тех, кому не отправляли** («сколько купили без скидки»).
* **Uplift = CR_t − CR_c** — «чистая прибавка» от скидки (в процентных пунктах).
* **Wasted% = CR_c / CR_t** — доля «бесполезных» скидок (люди, которые и так купили бы). Чем выше — тем меньше смысл рассылать.
* **ExtraOrders@K** — сколько дополнительных заказов дала скидка в выбранном охвате (top-K):
  разница конверсий *(CR_t − CR_c)* умножается на число получивших скидку в этом сегменте.
* **NetEffect (грубо)** — *ExtraOrders@K × AOV − DiscountCost@K*. Если ≥ 0 — сегмент выгоден.

**Как применяю.** Сортирую клиентов по скору модели и смотрю верхние сегменты — 
например, **top-10% / 20% / 30%** базы. В каждом сегменте считаю показатели выше и оставляю в рассылке только те сегменты, 
где **Uplift > 0**, **Wasted% невысокий** и **NetEffect не отрицательный**.


### 1.5 Мини-критерии успеха для учебного проекта

* В выбранном верхнем сегменте: **CR_t выше CR_c** (uplift положительный).
* **Wasted%** в этом сегменте **не высокий** (ориентир: ≤ 30–40%).
* **NetEffect ≥ 0** (дополнительные заказы перекрывают стоимость скидок).
* (**ROC-AUC ≥ 0.75** и **F1 ≥ 0.70** на тесте — как проверка адекватности модели.)

